# -*- coding: utf-8 -*-
"""Recommender_system_script.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17CfrtXDS2X8M3wdyMKNjvv01ukd1OZcb
"""

class RecommenderSystem:

  """
  Рекомендательная система
  """

  def __init__(self, df_dir_path):

    #Товар
    self.products_id = []
    self.prod_name = None

    #Путь до "сырых" данных о покупателях и транзакциях
    self.df_transactions = pd.read_csv(df_dir_path + '/transactions.csv')
    self.df_products = pd.read_csv(df_dir_path + '/products.csv')
    self.unq_users = self.df_transactions.user_id.unique().tolist()

    #Матрицы и датасеты
    self.total_df_counter = None
    self.df_category = None
    self.sparse_item_user = None
    self.sparse_user_item = None
    self.sparse_user_item_rank = None
    self.nn_train_df = None

    #Модели
    self.als_model = None
    self.lightfm_model = None
    self.nn_model = None


  def load_raw_df(self, df_transactions=True):

    """
    Загрузить сырые датасеты продуктов и транзакций
    Если флаг data_transactions = True, то загрузится датасет с транзакциями
    """

    if df_transactions: 
      return self.df_transactions
    else:
      return self.df_products


  def prepare_data_counter(self, counter_data_path):

    """
    Функция для подсчитывания заказов
    Время выполнения функции 1 час
    couner_data_path - Путь куда сохранять данные пользователей
    """
    
    #Создадим словарь пользователь: количество покупок
    users_count_dict = {}

    for i in tqdm(self.unq_users):
      #Берем каждого юзера отдельно
      user_tr = self.df_transactions[self.df_transactions.user_id == i]
      #Создаем список покупок i-го юзера
      order_list = user_tr.product_id
      #Подсчитываем количесвто купелного товара
      count_pr = (order_list.value_counts())
      #В словарь
      count_pr_dict = count_pr.to_dict()

      users_count_dict[i] = count_pr_dict

    #Переформатируем в более удобный вид
    counter_arr = []

    for i in users_count_dict.keys():
      for products, amount in users_count_dict[i].items():
        counter_arr.append([i, products, amount])

    counter_df = pd.DataFrame(counter_arr, 
                              columns=['user_id', 'product_id', 'count'])
    
    #Сохраним полученный датасет
    counter_df.to_csv(counter_data_path + '/counter_df', index=False)


  def load_counter_df(self, df_counter_path):
    """
    Загрузить датасет с количеством купленных продуктов по юзерам
    Если df_counter уже посчитан
    df_counter_path - укажите путь до датасета counter_df
    """
    self.total_df_counter = pd.read_csv(df_counter_path + '/counter_df')


  def categ_df(self, df_path):

    """
    Функция для категоризации данных
    Необходимо выполнить функцию перед формированием sparse_matrix
    """

    self.df_category = self.total_df_counter.copy()

    self.df_category['user_id'] = self.df_category['user_id'].astype('category')
    self.df_category['product_id'] = self.df_category['product_id'].astype('category')
    self.df_category['count'] = self.df_category['count'].astype('category')

    self.df_category['user'] = self.df_category['user_id'].cat.codes
    self.df_category['product'] = self.df_category['product_id'].cat.codes
    self.df_category['count'] = self.df_category['count'].cat.codes

    #Сохранить датасет с категориями
    # self.df_category.to_csv(df_path + '/df_with_cat', index=False)


  def sparse_matrix(self):

    """
    Функция для создания разряженных матриц
    Разряженные матрицы необходимы для работы с ALS алгоритмом
    """

    self.sparse_item_user = sparse.csr_matrix(
        (self.df_category['count'].astype(float),
         (self.df_category['product'], self.df_category['user']))
        )
    
    self.sparse_user_item = sparse.csr_matrix(
        (self.df_category['count'].astype(float),
         (self.df_category['user'], self.df_category['product']))
        )


  def top_prod(self, user=None, n_products=10):

    """
    Показать ТОП-N продуктов которые выбрал пользователь
    user - пользователь для которого необходимо показать ТОП продуктов
    n_products - количество продуктов (по умол. 10)
    """

    #Выберем user
    df_user_top = self.df_transactions[self.df_transactions.user_id == user]

    #Посчитаем какое количество продуктов купил user
    df_count_products = pd.DataFrame(df_user_top.groupby(['user_id',
                                                          'product_id']).count()['reordered'])
    df_count_products.rename(columns = {'reordered' : 'count'}, inplace = True)
    df_count_products.reset_index(1, inplace = True)

    #Создадим ТОП продуктов для user
    df_top = df_count_products.groupby('user_id', sort=False)\
    .apply(lambda x: x.sort_values('count', ascending=False).head(n_products))

    #Создадим таблицу ТОП
    df_top_n = pd.DataFrame()
    df_top_n['user_id'] = df_user_top.user_id.unique()
    df_top_n.index = df_top_n['user_id']
    df_top_n['product_id'] = df_top.groupby('user_id')['product_id'].agg(list)

    list_top = df_top_n['product_id'].tolist()[0]

    self.products_id = list_top

    return list_top


  def ALS_algo(self):

    """
     Алгоритм ALS
     Функция для обучения модели
    """

    self.als_model = implicit.als.AlternatingLeastSquares(factors=1000,
                                                          regularization=0.0,
                                                          iterations=10)
    self.als_model.fit(self.sparse_user_item)
  

  def ALS_predict(self, user=None, n_products=10):

    """
     Алгоритм ALS
     Функция для предсказания
     user - номер пользователя
     n_products - количество рекомендаций
    """

    #df для декодирования продуктов
    uncode_pr = pd.DataFrame()
    uncode_pr['product'] = self.df_category['product'].unique()
    uncode_pr['product_id'] = self.df_category['product_id'].unique()
    uncode_pr.index = self.df_category['product'].unique()

    #df для декодирования users
    uncode_user = pd.DataFrame()
    uncode_user['user'] = self.df_category['user'].unique()
    uncode_user['user_id'] = self.df_category['user_id'].unique()
    uncode_user.index = self.df_category['user_id'].unique()

    try:
      user_cat = uncode_user.at[user, 'user']
    except KeyError:
      print('Нет пользователя с таким id!')

    prediction = self.als_model.recommend(user_cat,
                                          self.sparse_item_user,
                                          N=n_products,
                                          filter_already_liked_items=False,
                                          recalculate_user=False)[0].tolist()
    pred = []
    for n in prediction:
      id_pr = uncode_pr.at[n, 'product_id']
      pred.append(id_pr)

    self.products_id = pred

    return pred



  def LightFM_prepare_df(self):

    """
     Алгоритм LightFM
     Функция для подготовки данных и обучения модели
     LightFM работает с рейтингами. 
     Сформируем рейтинги каждого продукта. 
     Самый частый продукт будет с рейтингом 1.
    """

    df_rank = self.total_df_counter
    df_rank['rank_pr'] = None

    #Берем значения
    df_values=df_rank[['user_id','product_id','count']].values

    n=1
    rank = []
    user_n = df_values[0][0]
    prod_n = df_values[0][1]
    count_n = df_values[0][2]
    rank.append(n)

    #Проходим по массиву и выставляем ранг
    for row in df_values[1:]:

      if row[0] == user_n:
        if row[2] == count_n:
          rank.append(n)
          count_n = row[2]
        else:
          n += 1
          rank.append(n)
          count_n = row[2]
      
      else:
        n=1    

        user_n = row[0]
        prod_n = row[1]
        count_n = row[2]
        rank.append(n)

    #Добавляем список рангов в датасет
    df_rank.loc[:, 'rank_pr'] = rank

    #Перевернем ранги, так как LightFM работаем с максимальным рангом
    df_rank.rank_pr = (df_rank.rank_pr.max() +1) - df_rank.rank_pr
    df_rank = df_rank.drop('count', axis = 1)

    #Создадим разряженную матрицу
    self.sparse_user_item_rank = sparse.csr_matrix((df_rank['rank_pr'].astype(float), 
                                                    (df_rank['user_id'], 
                                                     df_rank['product_id']),))
    
    print('Sparse matrix готова!')
    

  def LightFM_algo(self):  
    #Создадим модель
    self.lightfm_model = LightFM(no_components=20, loss='warp')

    #Обучение
    self.lightfm_model.fit(self.sparse_user_item_rank, epochs=100)


  def LightFM_predict(self, user=None, n_products=10):


    """
     Алгоритм LightFM
     Функция для предсказания
     user - номер пользователя
     n_products - количество рекомендаций
    """

    prediction = self.lightfm_model.predict(int(user), 
                                            np.arange(self.sparse_user_item_rank.shape[1]))
    top_items = np.argsort(-prediction)
    top_items = top_items[:n_products].tolist()

    self.products_id = top_items

    return top_items


  def NNetwork(self):
    '''
    Нейронная сеть
    Формируются датасеты и архитектура
    Заранее должны быть загружены датасеты df_transactions, total_df_counter
    '''

    #Описание user
    #[id_user, Кол-во купленных товаров, Перезаказ товаров]
    emb_user_df = pd.DataFrame()
    emb_user_df['user_id'] = self.df_transactions.user_id.unique()
    emb_user_df.index = self.df_transactions.user_id.unique()
    emb_user_df['prod_count'] = self.df_transactions.groupby('user_id').count()['reordered']
    emb_user_df['reordered_pr'] = round((self.df_transactions.groupby('user_id')\
                                        .sum()['reordered'] * 100) / self.df_transactions.groupby('user_id').count()['reordered'], 2)
    
    #Описание item
    #[id_product, Сколько всего купили этот товар, 
    # Процент перезаказа этого товара, Количество купленного товара конкретным user]
    emb_item_df = pd.DataFrame()
    emb_item_df['product_id'] = self.df_transactions.product_id.unique()
    emb_item_df.index = self.df_transactions.product_id.unique()
    emb_item_df['prod_count_total'] = self.df_transactions.groupby('product_id').count()['reordered']
    emb_item_df['reordered_pr_total'] = round((self.df_transactions.groupby('product_id')\
                                        .sum()['reordered'] * 100) / self.df_transactions.groupby('product_id').count()['reordered'], 2)
    
    #Объединим все таблицы в одну train_df
    self.nn_train_df = self.df_transactions.loc[:, ['user_id', 'product_id', 'reordered']].copy()
    self.nn_train_df = self.nn_train_df.merge(emb_user_df, on='user_id')
    self.nn_train_df = self.nn_train_df.merge(emb_item_df, on='product_id')
    self.nn_train_df = self.nn_train_df.merge(self.total_df_counter, on=['user_id', 'product_id'])


    #АРХИТЕКТРА
    #Кол-во users и items
    num_users = len(pd.unique(self.nn_train_df.user_id)) +1
    num_items = len(pd.unique(self.nn_train_df.product_id)) +1
    #Создаем два входных слоя
    user_input = tf.keras.layers.Input(shape=(3,), dtype='int32', name = 'user_input')
    item_input = tf.keras.layers.Input(shape=(4,), dtype='int32', name = 'item_input')
    #Вытягиваем и склеиваем в один слой
    user_latent = tf.keras.layers.Flatten()(user_input)
    item_latent = tf.keras.layers.Flatten()(item_input)
    vector = tf.keras.layers.Concatenate()([user_latent, item_latent])
    #Слои модели после склеивания эмбеддингов
    layer1 = tf.keras.layers.Dense(64, input_shape = (num_users+num_items, ), activation='relu')(vector)
    layer2 = tf.keras.layers.Dense(32, activation='relu')(layer1)
    layer3 = tf.keras.layers.Dense(16, activation='relu')(layer2)
    output_layer = tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer='l2')(layer3)
    #Модель
    self.nn_model = tf.keras.Model(inputs=[user_input, item_input], outputs=[output_layer])
    #Компиляция
    optimizer = tf.keras.optimizers.Adam(lr = 0.001)
    loss = tf.keras.losses.binary_crossentropy
    self.nn_model.compile(optimizer=optimizer, loss=loss, metrics=['MSE'])


  def NNetwork_fit(self, user=None, n_products=10, weight = False, weight_path=None):

    

    if weight:
      self.nn_model.load_weights(weight_path + '/checkpoint_best_5epochs')
    else:
      y = self.nn_train_df['reordered']
      self.nn_model.fit([self.nn_train_df.loc[:, ['user_id', 'prod_count', 'reordered_pr']], 
                   self.nn_train_df.loc[:, ['product_id', 'prod_count_total', 'reordered_pr_total', 'count']]], 
                    y, 
                    epochs=5)
        
    train_df_predict = self.nn_train_df[self.nn_train_df.reordered == 0]
    prediction_df = train_df_predict[train_df_predict.user_id == user]
    prediction_df['Prediction'] = None
    user_emb = train_df_predict[train_df_predict.user_id == user][['user_id', 
                                                             'prod_count',
                                                             'reordered_pr']]

    item_emb = train_df_predict[train_df_predict.user_id == user][['product_id',
                                                              'prod_count_total',
                                                              'reordered_pr_total',
                                                              'count']]
    prediction =  self.nn_model.predict([user_emb, item_emb], batch_size=20, verbose=False).reshape(-1)
    prediction_df.loc[item_emb.index, 'Prediction'] = prediction
    prediction_df_total = prediction_df.sort_values('Prediction', ascending=False)['product_id'].head(n_products)
    self.products_id = prediction_df_total.tolist()
  
  def NNetwork_result(self):
    print(self.products_id)


        

  def download_image_products(self):

    """
    Фунцкия для парсинга изображений продуктов из интернета
    Сохраняются в папку image
    """

    #Спарсим изображение ошибки
    error_image = GoogleImageCrawler(
        parser_threads=2,
        downloader_threads=4,
        storage={'root_dir': 'images/error_image'})
    error_image.crawl(
        keyword='error_image', max_num=1, 
        filters=dict(size='icon'), 
        min_size=(128, 128))


    self.prod_name = []
    for pr_id in self.products_id:
      pr_name = df_prod[df_prod['product_id'] == pr_id]['product_name'].values[0]
      self.prod_name.append(pr_name)

    #Парсим изображения
    for keyword in self.prod_name:
        google_crawler = GoogleImageCrawler(
            parser_threads=2,
            downloader_threads=4,
            storage={'root_dir': 'images/{}'.format(keyword)})

        google_crawler.crawl(
            keyword=keyword, max_num=1, 
            filters=dict(size='icon'), 
            min_size=(128, 128))
        

  def show_products(self):
    """
    Функция для отображения сохраненных изображений
    """
    #Выводим изображения
    prod_pictures = plt.figure(figsize=(16,4))
    for i, picture in enumerate(self.prod_name):
      try:
        name = picture
        #Изображение в picture
        picture = cv2.imread(f'images/{picture}/' + '000001.jpg')
        #BGR --> RGB
        picture = cv2.cvtColor(picture, cv2.COLOR_BGR2RGB)
      except:
        print('Ошибка отображения')
        picture = cv2.imread('images/error_image/' + '000001.png')
        prod_pictures.add_subplot(1,len(self.prod_name),i+1)
        plt.imshow(picture)
        # plt.title(name)
        plt.axis('off')
      else:
        prod_pictures.add_subplot(1,len(self.prod_name),i+1)
        plt.imshow(picture)
        # plt.title(name)
        plt.axis('off')
    plt.show()